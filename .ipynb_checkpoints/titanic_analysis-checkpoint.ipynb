{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 19, 12\n",
    "import seaborn as sns\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")\n",
    "test_set = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Data\n",
    "### 2.1. Check data type and whether the column contain null data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Train----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "----Test----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"----Train----\")\n",
    "print(dataset.info())\n",
    "print(\"----Test----\")\n",
    "print(test_set.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results shows that there are three columns(Age, Cabin, Embarked) contains null in train dataset,  \n",
    "and four columns(Age, Fare, Cabin, Embarked) contains null in test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### やるべきこと\n",
    "* 補完\n",
    "* カテゴリ⇒数値化\n",
    "\n",
    "補完についてはObject Typeで必要なものはCabin、Embarkedであり、数値型で必要なものはAge、Fareがある。\n",
    "\n",
    "まず、補完の必要のないカテゴリデータを数値化し、次に数値型の補完を行い、最後にどちらも必要なものに対して処理を行う。\n",
    "\n",
    "### 順番\n",
    "1. カテゴリの数値化（Name, Sex, Ticket）\n",
    "2. 数値型の補完（Age, Fare）\n",
    "3. 補完とカテゴリの数値化（Cabin, Embarked）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Encode object to one hot.\n",
    "\n",
    "We should encode object to one hot.\n",
    "Columns have object type are Name, Sex, Ticket, Cabin and Embarked.\n",
    "\n",
    "Next we visualize these data and preprocess one hot encoding for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0\n",
      "347082        7\n",
      "CA. 2343      7\n",
      "1601          7\n",
      "3101295       6\n",
      "CA 2144       6\n",
      "347088        6\n",
      "S.O.C. 14879  5\n",
      "382652        5\n",
      "LINE          4\n",
      "PC 17757      4\n"
     ]
    }
   ],
   "source": [
    "count_ticket = collections.Counter(dataset[\"Ticket\"])\n",
    "count_ticket = pd.DataFrame(list(count_ticket.values()), index=count_ticket.keys())\n",
    "count_ticket = count_ticket.sort_values(0, ascending=False)\n",
    "print(count_ticket.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticketの変換  \n",
    "（１）先頭文字を抽出　⇒　パターンで分類（置換）　⇒　数値化  \n",
    "\n",
    "（２）文字数を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_ticket(data):\n",
    "    dataset = data.copy()\n",
    "    test = dataset['Ticket'].apply(lambda x: str(x)[0])\n",
    "    dataset[\"Ticket_header\"] = np.where((test).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), test,\n",
    "            np.where((test).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0'))\n",
    "\n",
    "    dataset[\"Ticket_header\"] = dataset[\"Ticket_header\"].replace(\"1\",1).replace(\"2\",2).replace(\"3\",3).replace(\"0\",0).replace(\"S\",3).replace(\"P\",0).replace(\"C\",3).replace(\"A\",3)\n",
    "    dataset[\"Ticket_header\"]\n",
    "    dataset[\"Ticket_Len\"] = dataset[\"Ticket\"].apply(lambda x: len(x)) \n",
    "    del dataset['Ticket'] \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = translate_ticket(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Dead        or           Alive')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20e715237b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(4):\n",
    "    plt.hist(train_set[train_set[\"Ticket_header\"] == k][\"Survived\"]+k/10,\n",
    "         normed=True, label=str(k))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dead        or           Alive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_Name(data):\n",
    "    dataset = data.copy()\n",
    "    dataset['Salutation'] = dataset.Name.str.extract(' ([A-Za-z]+).', expand=False)\n",
    "    rare = ['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace(rare, 'Rare')\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace(['Mlle','Ms'], 'Miss')\n",
    "    dataset['Salutation'] = dataset['Salutation'].replace('Mme', 'Mrs')\n",
    "    Salutation_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \n",
    "    dataset['Salutation'] = dataset['Salutation'].map(Salutation_mapping) \n",
    "    dataset['Salutation'] = dataset['Salutation'].fillna(0)\n",
    "    del dataset['Name']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = translate_Name(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_Cabin(data):\n",
    "    dataset = data.copy()\n",
    "    dataset['Cabin_header'] = dataset['Cabin'].apply(lambda x: str(x)[0]) \n",
    "    dataset['Cabin_header'] = dataset['Cabin_header'].apply(lambda x: str(x)) \n",
    "    dataset['Cabin_header'] = np.where((dataset['Cabin_header']).isin([ 'F', 'E', 'D', 'C', 'B', 'A']),\n",
    "                                       dataset['Cabin_header'], np.where((dataset['Cabin_header']).isin(['W', '4', '7', '6', 'L', '5', '8']), '0','0'))\n",
    "    del dataset['Cabin'] \n",
    "    dataset['Cabin_header']=dataset['Cabin_header'].replace(\"A\",1).replace(\"B\",2).replace(\"C\",1).replace(\"0\",0).replace(\"D\",2).replace(\"E\",2).replace(\"F\",1)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = translate_Cabin(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_SibSp_Parch(data):\n",
    "    dataset = data.copy()\n",
    "    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    del dataset[\"SibSp\"]\n",
    "    del dataset[\"Parch\"]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = translate_SibSp_Parch(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, column, drop_first):\n",
    "    dataset = data.copy()\n",
    "    add_df = pd.get_dummies(dataset[column], drop_first=False)\n",
    "    del dataset[column]\n",
    "    return pd.concat([dataset, add_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = one_hot_encoding(train_set, \"Sex\", drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId      891 non-null int64\n",
      "Survived         891 non-null int64\n",
      "Pclass           891 non-null int64\n",
      "Age              714 non-null float64\n",
      "Fare             891 non-null float64\n",
      "Embarked         889 non-null object\n",
      "Ticket_header    891 non-null int64\n",
      "Ticket_Len       891 non-null int64\n",
      "Salutation       891 non-null float64\n",
      "Cabin_header     891 non-null int64\n",
      "FamilySize       891 non-null int64\n",
      "IsAlone          891 non-null int64\n",
      "female           891 non-null uint8\n",
      "male             891 non-null uint8\n",
      "dtypes: float64(3), int64(8), object(1), uint8(2)\n",
      "memory usage: 85.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠損値の補完\n",
    "\n",
    "### 欠損タイプ\n",
    "* MCAR(Missing Completely At Random)  \n",
    "偶然起きているランダムな欠損\n",
    "* MAR(Missing At Random)  \n",
    "欠損項目と関係なく、他の項目に依存した欠損（湿度が高い程、温度データが欠損しやすい）\n",
    "* MNAR(Missing Not At Random)  \n",
    "欠損項目に依存した欠損（ある温度以上は欠損する）\n",
    "\n",
    "### 対処\n",
    "* 削除  \n",
    "簡単だがバイアスの発生とデータ数の減少というデメリットがある\n",
    "* 補完  \n",
    "適した手法を適用する必要があるが、柔軟性がある\n",
    "\n",
    "### 補完手法種類\n",
    "* 定数補完\n",
    "* 集計値補完\n",
    "* 予測値補完\n",
    "* 時系列補完  \n",
    "MCAR、MARにおいて有効\n",
    "* 多重代入法  \n",
    "MCAR、MARにおいて有効\n",
    "* 最尤法  \n",
    "MCAR、MARにおいて有効\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/hyperopt/hyperopt.git\n",
      "  Cloning git://github.com/hyperopt/hyperopt.git to c:\\users\\morinibu\\appdata\\local\\temp\\pip-req-build-pameo3pc\n",
      "fatal: Unable to look up github.com (port 9418) (そのようなホストは不明です。 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"git clone -q git://github.com/hyperopt/hyperopt.git C:\\Users\\morinibu\\AppData\\Local\\Temp\\pip-req-build-pameo3pc\" failed with error code 128 in None\n"
     ]
    }
   ],
   "source": [
    "#!pip install fancyimpute --proxy http://morinibu:tM231615@10.30.26.11:3128\n",
    "!pip install --upgrade git+git://github.com/hyperopt/hyperopt.git --proxy http://morinibu:tM231615@10.30.26.11:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN  \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Embarked.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def KNN_complement(data):\n",
    "    dataset = data.copy()\n",
    "    train = dataset[[not(t) for t in dataset.Embarked.isnull()]]\n",
    "    test = dataset[dataset.Embarked.isnull()]\n",
    "    \n",
    "    train_col = ['Pclass', 'Fare',\n",
    "           'Ticket_header', 'Ticket_Len', 'Salutation', 'Cabin_header',\n",
    "           'FamilySize', 'IsAlone', 'female', 'male']\n",
    "    X_train = train[train_col]\n",
    "    y_train = train[\"Embarked\"]\n",
    "    test = test[train_col]\n",
    "    \n",
    "    KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    # print(KNN.score(X_train, y_train))\n",
    "    dataset.Embarked[test.index.difference(X_train)] = KNN.predict(test)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morinibu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_set = KNN_complement(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C': 168, 'Q': 77, 'S': 646})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(train_set.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId      891 non-null int64\n",
      "Survived         891 non-null int64\n",
      "Pclass           891 non-null int64\n",
      "Age              714 non-null float64\n",
      "Fare             891 non-null float64\n",
      "Embarked         891 non-null object\n",
      "Ticket_header    891 non-null int64\n",
      "Ticket_Len       891 non-null int64\n",
      "Salutation       891 non-null float64\n",
      "Cabin_header     891 non-null int64\n",
      "FamilySize       891 non-null int64\n",
      "IsAlone          891 non-null int64\n",
      "female           891 non-null uint8\n",
      "male             891 non-null uint8\n",
      "dtypes: float64(3), int64(8), object(1), uint8(2)\n",
      "memory usage: 85.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading https://files.pythonhosted.org/packages/39/51/16e9edb51ffbf64bd80f41b7d30bc037aa8b157d430c276464c9b8768b67/hyperopt-0.1.tar.gz (98kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: nose in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (1.3.7)\n",
      "Collecting pymongo (from hyperopt)\n",
      "  Downloading https://files.pythonhosted.org/packages/46/39/b9bb7fed3e3a0ea621a1512a938c105cd996320d7d9894d8239ca9093340/pymongo-3.6.1-cp36-cp36m-win_amd64.whl (291kB)\n",
      "Requirement already satisfied: six in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (2.1)\n",
      "Requirement already satisfied: future in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperopt) (0.16.0)\n",
      "Requirement already satisfied: decorator>=4.1.0 in c:\\users\\morinibu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from networkx->hyperopt) (4.2.1)\n",
      "Building wheels for collected packages: hyperopt\n",
      "  Running setup.py bdist_wheel for hyperopt: started\n",
      "  Running setup.py bdist_wheel for hyperopt: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\morinibu\\AppData\\Local\\pip\\Cache\\wheels\\32\\69\\f5\\3267146c22e76dbf8c5e13a535d3c00b9efabe58883a0da65d\n",
      "Successfully built hyperopt\n",
      "Installing collected packages: pymongo, hyperopt\n",
      "Successfully installed hyperopt-0.1 pymongo-3.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "notebook 5.4.0 requires ipykernel, which is not installed.\n",
      "jupyter 1.0.0 requires ipykernel, which is not installed.\n",
      "jupyter-console 5.2.0 requires ipykernel, which is not installed.\n",
      "ipywidgets 7.1.1 requires ipykernel>=4.5.1, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "! pip install hyperopt --proxy http://morinibu:tM231615@10.30.26.11:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_parameters = {\n",
    "    'C': hp.uniform('C', 0, 2),\n",
    "    'gamma': hp.loguniform('gamma', -8, 2),\n",
    "    'kernel': hp.choice('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    # モデルのインスタンス化\n",
    "    classifier = SVC(**args)\n",
    "    # trainデータを使ってモデルの学習\n",
    "    classifier.fit(x_train, y_train)\n",
    "    # validationデータを使用して、ラベルの予測\n",
    "    predicts = classifier.predict(x_test)\n",
    "    # 予測ラベルと正解ラベルを使用してmicro f1を計算\n",
    "    f1 = f1_score(y_test, predicts, average='micro')\n",
    "    # 今回はmicro f1を最大化したいので、-1をかけて最小化に合わせる\n",
    "    return -1*f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-d6a5e7b7d3cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     domain = base.Domain(fn, space,\n\u001b[1;32m--> 314\u001b[1;33m                          pass_expr_memo_ctrl=pass_expr_memo_ctrl)\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     rval = FMinIter(algo, domain, trials, max_evals=max_evals,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, expr, workdir, pass_expr_memo_ctrl, name, loss_target)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mbefore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# -- raises exception if expr contains cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[0mpyll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoposort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m         \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorizeHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms_new_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[1;31m# -- raises exception if v_expr contains cycles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\hyperopt\\pyll\\base.py\u001b[0m in \u001b[0;36mtoposort\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_in\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopological_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# iterationする回数\n",
    "max_evals = 200\n",
    "# 試行の過程を記録するインスタンス\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    # 最小化する値を定義した関数\n",
    "    objective,\n",
    "    # 探索するパラメータのdictもしくはlist\n",
    "    hyperopt_parameters,\n",
    "    # どのロジックを利用するか、基本的にはtpe.suggestでok\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col = ['Pclass', 'Fare',\n",
    "           'Ticket_header', 'Ticket_Len', 'Salutation', 'Cabin_header',\n",
    "           'FamilySize', 'IsAlone', 'female', 'male']\n",
    "X_train = train_set[train_col]\n",
    "y_train = train_set[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
